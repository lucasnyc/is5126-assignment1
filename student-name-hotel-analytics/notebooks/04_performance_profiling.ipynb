{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a0190c",
   "metadata": {},
   "source": [
    "# Performance Profiling for Hotel Review Analytics\n",
    "\n",
    "This notebook focuses on **performance profiling** for our hotel analytics platform used by HospitalityTech Solutions’ hotel clients. We work with reviews to ensure that real-world data scale is reflected, and we demonstrate how both **Python code** and **SQLite queries** behave under load.\n",
    "\n",
    "Our business goal in this notebook is to:\n",
    "- Ensure that core analytics operations (filtering, aggregations, joins, clustering) run fast enough for interactive dashboards.\n",
    "- Quantify performance gains from optimizations (in-memory filtering vs full data, database indexing, and code-level profiling).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdf7f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import time\n",
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3951f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.read_csv('data/reviews.csv')\n",
    "author_df = pd.read_csv('data/authors.csv')\n",
    "hotel_df = pd.read_csv('data/hotels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff47d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_review_df = review_df.dropna().drop_duplicates(subset=['text']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab748c6e",
   "metadata": {},
   "source": [
    "## Baseline Dataset Overview and Memory Footprint\n",
    "\n",
    "We first inspect the size and structure of our cleaned review data: [file:1]\n",
    "\n",
    "- **Review table shape**: total number of reviews and columns after basic cleaning.  \n",
    "- **Hotel table shape**: number of hotels we can analyze and benchmark.  \n",
    "- **Author table shape**: number of unique reviewers, enabling analysis of review helpfulness and reviewer behavior.  \n",
    "\n",
    "We also compute **deep memory usage** for `cleaned_review_df` to understand how much RAM our analytics pipeline consumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "554cbdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW TABLE SHAPE: (754798, 16)\n",
      "REVIEW (FILTERED) TABLE SHAPE: (343758, 16)\n",
      "HOTEL TABLE SHAPE: (3888, 1)\n",
      "AUTHOR TABLE SHAPE: (524023, 7)\n",
      "\n",
      "Memory Usage (Full Review Dataset)\n",
      "<class 'pandas.DataFrame'>\n",
      "Index: 343758 entries, 0 to 754789\n",
      "Data columns (total 16 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   id                        343758 non-null  int64  \n",
      " 1   author_id                 343758 non-null  str    \n",
      " 2   offering_id               343758 non-null  int64  \n",
      " 3   overall                   343758 non-null  float64\n",
      " 4   service                   343758 non-null  float64\n",
      " 5   cleanliness               343758 non-null  float64\n",
      " 6   value                     343758 non-null  float64\n",
      " 7   location_rating           343758 non-null  float64\n",
      " 8   sleep_quality             343758 non-null  float64\n",
      " 9   rooms                     343758 non-null  float64\n",
      " 10  title                     343758 non-null  str    \n",
      " 11  text                      343758 non-null  str    \n",
      " 12  review_date               343758 non-null  str    \n",
      " 13  date_stayed               343758 non-null  str    \n",
      " 14  via_mobile                343758 non-null  bool   \n",
      " 15  author_num_helpful_votes  343758 non-null  float64\n",
      "dtypes: bool(1), float64(8), int64(2), str(5)\n",
      "memory usage: 448.3 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"REVIEW TABLE SHAPE:\", review_df.shape)\n",
    "print(\"REVIEW (FILTERED) TABLE SHAPE:\", cleaned_review_df.shape)\n",
    "print(\"HOTEL TABLE SHAPE:\", hotel_df.shape)\n",
    "print(\"AUTHOR TABLE SHAPE:\", author_df.shape)\n",
    "\n",
    "print(\"\\nMemory Usage (Full Review Dataset)\")\n",
    "cleaned_review_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebb89ba",
   "metadata": {},
   "source": [
    "## Prioritizing High-Quality Reviews (80th Percentile Filter)\n",
    "\n",
    "To improve both **business relevance** and **performance**, we filter reviews based on `author_num_helpful_votes`.\n",
    "\n",
    "- We compute the **80th percentile** threshold of helpful votes across all reviews.  \n",
    "- We keep only reviews where `author_num_helpful_votes` is at or above this threshold.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dc35ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80th Percentile Threshold: 22.0\n",
      "Rows Before: 754798\n",
      "Rows After: 71102\n",
      "Filtering Time: 0.0253 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "threshold_80 = np.percentile(\n",
    "    cleaned_review_df['author_num_helpful_votes'].dropna(),\n",
    "    80\n",
    ")\n",
    "\n",
    "filtered_reviews = cleaned_review_df[\n",
    "    cleaned_review_df['author_num_helpful_votes'] >= threshold_80\n",
    "].copy()\n",
    "\n",
    "end = time.time()\n",
    "filter_time = end - start\n",
    "\n",
    "print(\"80th Percentile Threshold:\", threshold_80)\n",
    "print(\"Rows Before:\", review_df.shape[0])\n",
    "print(\"Rows After:\", filtered_reviews.shape[0])\n",
    "print(\"Filtering Time:\", round(filter_time, 4), \"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81460500",
   "metadata": {},
   "source": [
    "## Measuring Core Analytics Operations (Full vs Filtered Data)\n",
    "\n",
    "Two operations are central to the hotel analytics platform:\n",
    "\n",
    "1. **Aggregation**: computing average ratings per hotel (e.g., `overall` score grouped by `offering_id`).  \n",
    "2. **Join**: merging review data with hotel master data so each hotel’s metrics appear with its attributes (name, location, etc.).  \n",
    "\n",
    "We measure how long these operations take on:  \n",
    "- The **full dataset** (all reviews).  \n",
    "- The **filtered dataset** (top 20% most helpful reviews).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c81872a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Time (Full Data): 0.0189 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "agg_full = review_df.groupby(\"offering_id\")[\"overall\"].mean()\n",
    "\n",
    "end = time.time()\n",
    "agg_full_time = end - start\n",
    "\n",
    "print(\"Aggregation Time (Full Data):\", round(agg_full_time, 4), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "773053e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Join Time (Full Data): 0.0324 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "merged_full = review_df.merge(\n",
    "    hotel_df,\n",
    "    on=\"offering_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "join_full_time = end - start\n",
    "\n",
    "print(\"Join Time (Full Data):\", round(join_full_time, 4), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0cb928d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Time (Filtered Data): 0.0026 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "agg_filtered = filtered_reviews.groupby(\"offering_id\")[\"overall\"].mean()\n",
    "\n",
    "end = time.time()\n",
    "agg_filtered_time = end - start\n",
    "\n",
    "print(\"Aggregation Time (Filtered Data):\", round(agg_filtered_time, 4), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1246d8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Join Time (Filtered Data): 0.0056 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "merged_filtered = filtered_reviews.merge(\n",
    "    hotel_df,\n",
    "    on=\"offering_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "join_filtered_time = end - start\n",
    "\n",
    "print(\"Join Time (Filtered Data):\", round(join_filtered_time, 4), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b97cc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Operation</th>\n",
       "      <th>Full Data Time (sec)</th>\n",
       "      <th>Filtered Data Time (sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aggregation</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Join</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Operation  Full Data Time (sec)  Filtered Data Time (sec)\n",
       "0  Aggregation                0.0189                    0.0026\n",
       "1         Join                0.0324                    0.0056"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_summary = pd.DataFrame({\n",
    "    \"Operation\": [\n",
    "        \"Aggregation\",\n",
    "        \"Join\"\n",
    "    ],\n",
    "    \"Full Data Time (sec)\": [\n",
    "        round(agg_full_time,4),\n",
    "        round(join_full_time,4)\n",
    "    ],\n",
    "    \"Filtered Data Time (sec)\": [\n",
    "        round(agg_filtered_time,4),\n",
    "        round(join_filtered_time,4)\n",
    "    ]\n",
    "})\n",
    "\n",
    "performance_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af82808",
   "metadata": {},
   "source": [
    "### Interpretation: Performance Gains from Filtering\n",
    "\n",
    "The summary table reports timing (in seconds) for aggregation and join operations on both full and filtered data.\n",
    "\n",
    "Typical pattern observed:\n",
    "\n",
    "- **Aggregation** time drops substantially (e.g., ~0.019 s → ~0.003 s).  \n",
    "- **Join** time also improves (e.g., ~0.032 s → ~0.006 s).  \n",
    "\n",
    "**Business impact:**  \n",
    "If a dashboard repeatedly computes these metrics (e.g., when the user changes filters), the reduction in runtime translates into:\n",
    "\n",
    "- **Faster response times** for hotel managers.  \n",
    "- Ability to scale to more concurrent users or more complex analytics without upgrading hardware.  \n",
    "\n",
    "This demonstrates a clear trade-off: by focusing on high-helpfulness reviews, we gain **both quality and performance**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa04a562",
   "metadata": {},
   "source": [
    "## Moving to SQLite for Production-Like Workloads\n",
    "\n",
    "To align with the assignment requirement of using a **SQLite database** with 50K–80K reviews, we persist our filtered review data, hotel data, and author data into an on-disk database (`performance_testing.db`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acfe8148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524023"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"data/performance_testing.db\")\n",
    "\n",
    "filtered_reviews.to_sql(\"reviews\", conn, if_exists=\"replace\", index=False)\n",
    "hotel_df.to_sql(\"hotels\", conn, if_exists=\"replace\", index=False)\n",
    "author_df.to_sql(\"authors\", conn, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b40cb",
   "metadata": {},
   "source": [
    "## Query-Level Profiling: Average Ratings per Hotel\n",
    "\n",
    "We profile a key SQL query that computes **average aspect ratings per hotel**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0954e4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Time (Before Index): 0.1077 seconds\n"
     ]
    }
   ],
   "source": [
    "aggregation_query = \"\"\"\n",
    "SELECT offering_id,\n",
    "       AVG(service) AS avg_service,\n",
    "       AVG(cleanliness) AS avg_cleanliness,\n",
    "       AVG(value) AS avg_value\n",
    "FROM reviews\n",
    "GROUP BY offering_id\n",
    "\"\"\"\n",
    "\n",
    "start = time.time()\n",
    "baseline_result = pd.read_sql(aggregation_query, conn)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Aggregation Time (Before Index):\", round(end - start, 4), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbb3678e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  parent  notused                        detail\n",
      "0   6       0      216                  SCAN reviews\n",
      "1   8       0        0  USE TEMP B-TREE FOR GROUP BY\n"
     ]
    }
   ],
   "source": [
    "explain_query = \"EXPLAIN QUERY PLAN \" + aggregation_query\n",
    "print(pd.read_sql(explain_query, conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f955982d",
   "metadata": {},
   "source": [
    "## Optimization: Adding Index on `offering_id`\n",
    "\n",
    "**Business reasoning:**  \n",
    "Most hotel-level analytics group or filter by `offering_id`. Indexing this column should:  \n",
    "\n",
    "- Reduce I/O by allowing SQLite to locate groups more efficiently.  \n",
    "- Shorten query times, especially as review volume grows over multiple years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12a88b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "CREATE INDEX IF NOT EXISTS idx_reviews_offering\n",
    "ON reviews(offering_id)\n",
    "\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f91e69bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Time (After Index): 0.112 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "optimized_result = pd.read_sql(aggregation_query, conn)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Aggregation Time (After Index):\", round(end - start, 4), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a472ebdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  parent  notused                                         detail\n",
      "0   7       0      222  SCAN reviews USING INDEX idx_reviews_offering\n"
     ]
    }
   ],
   "source": [
    "print(pd.read_sql(explain_query, conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875a9bc7",
   "metadata": {},
   "source": [
    "### Interpretation: Impact of Indexing\n",
    "\n",
    "After adding the index, two key changes occur:\n",
    "\n",
    "- The query plan now shows `SCAN reviews USING INDEX idx_reviews_offering`, meaning SQLite leverages the index for grouping.  \n",
    "- Runtime is similar or slightly changed on this environment, but the **plan is now scalable** for larger datasets and more complex filters.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e171811",
   "metadata": {},
   "source": [
    "## Query-Level Profiling: Joining Reviews and Hotels\n",
    "\n",
    "We first measure the join performance before any index on the `hotels` table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d20d7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Join Time (Before Index):  0.1552 seconds\n"
     ]
    }
   ],
   "source": [
    "join_query = \"\"\"\n",
    "SELECT r.offering_id,\n",
    "       r.author_num_helpful_votes,\n",
    "       a.offering_id\n",
    "FROM reviews r\n",
    "JOIN hotels a\n",
    "ON r.offering_id = a.offering_id\n",
    "\"\"\"\n",
    "\n",
    "start = time.time()\n",
    "baseline_join_result = pd.read_sql(join_query, conn)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Join Time (Before Index): \", round(end - start, 4), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4e9542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "CREATE INDEX IF NOT EXISTS idx_hotels_offering\n",
    "ON hotels(offering_id)\n",
    "\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2724f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Join Time (After Index):  0.1365 seconds\n"
     ]
    }
   ],
   "source": [
    "join_query = \"\"\"\n",
    "SELECT r.offering_id,\n",
    "       r.author_num_helpful_votes,\n",
    "       a.offering_id\n",
    "FROM reviews r\n",
    "JOIN hotels a\n",
    "ON r.offering_id = a.offering_id\n",
    "\"\"\"\n",
    "\n",
    "start = time.time()\n",
    "baseline_join_result = pd.read_sql(join_query, conn)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Join Time (After Index): \", round(end - start, 4), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219f004c",
   "metadata": {},
   "source": [
    "## Code-Level Profiling: Pandas Aggregation\n",
    "\n",
    "Beyond database queries, we also profile **Python/Pandas code** to identify hotspots in our in-memory analytics pipeline.\n",
    "\n",
    "We define `pandas_aggregation()` to compute hotel-level averages (service, cleanliness, value, location_rating, sleep_quality, rooms) using `groupby().mean()` on the filtered review data. We then run `cProfile` and inspect the top functions by cumulative time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b5dabb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2243 function calls (2208 primitive calls) in 0.017 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 426 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      3/2    0.000    0.000    0.012    0.006 /Users/aviralgoyal/Desktop/NUS/Courses/Sem 2/IS5126 Hands-On Applied Analytics/A1/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3665(run_code)\n",
      "      3/2    0.000    0.000    0.012    0.006 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.011    0.011 /var/folders/hd/1qp006zn48sdflzfg6_25rtr0000gn/T/ipykernel_61141/3244918794.py:1(<module>)\n",
      "        1    0.000    0.000    0.011    0.011 /var/folders/hd/1qp006zn48sdflzfg6_25rtr0000gn/T/ipykernel_61141/3244918794.py:1(pandas_aggregation)\n",
      "        1    0.000    0.000    0.011    0.011 /Users/aviralgoyal/Desktop/NUS/Courses/Sem 2/IS5126 Hands-On Applied Analytics/A1/.venv/lib/python3.13/site-packages/pandas/core/groupby/groupby.py:2192(mean)\n",
      "        1    0.000    0.000    0.011    0.011 /Users/aviralgoyal/Desktop/NUS/Courses/Sem 2/IS5126 Hands-On Applied Analytics/A1/.venv/lib/python3.13/site-packages/pandas/core/groupby/groupby.py:1764(_cython_agg_general)\n",
      "        1    0.000    0.000    0.011    0.011 /Users/aviralgoyal/Desktop/NUS/Courses/Sem 2/IS5126 Hands-On Applied Analytics/A1/.venv/lib/python3.13/site-packages/pandas/core/internals/managers.py:1607(grouped_reduce)\n",
      "        1    0.000    0.000    0.010    0.010 /Users/aviralgoyal/Desktop/NUS/Courses/Sem 2/IS5126 Hands-On Applied Analytics/A1/.venv/lib/python3.13/site-packages/pandas/core/internals/blocks.py:341(apply)\n",
      "        1    0.000    0.000    0.010    0.010 /Users/aviralgoyal/Desktop/NUS/Courses/Sem 2/IS5126 Hands-On Applied Analytics/A1/.venv/lib/python3.13/site-packages/pandas/core/groupby/groupby.py:1781(array_func)\n",
      "        1    0.000    0.000    0.010    0.010 /Users/aviralgoyal/Desktop/NUS/Courses/Sem 2/IS5126 Hands-On Applied Analytics/A1/.venv/lib/python3.13/site-packages/pandas/core/groupby/ops.py:940(_cython_operation)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def pandas_aggregation():\n",
    "    return filtered_reviews.groupby('offering_id')[\n",
    "        ['service', 'cleanliness', 'value', 'location_rating', 'sleep_quality', 'rooms']\n",
    "    ].mean()\n",
    "\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "\n",
    "pandas_aggregation()\n",
    "\n",
    "pr.disable()\n",
    "\n",
    "s = io.StringIO()\n",
    "ps = pstats.Stats(pr, stream=s).sort_stats('cumtime')\n",
    "ps.print_stats(10)\n",
    "\n",
    "print(s.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603c8c29",
   "metadata": {},
   "source": [
    "## Preparing Hotel-Level Feature Profiles\n",
    "\n",
    "To support **competitive benchmarking** and segmentation, we construct a hotel-level feature matrix: \n",
    "\n",
    "- We group by `offering_id` and compute mean values for service, cleanliness, value, location_rating, sleep_quality, and rooms.  \n",
    "- We standardize these features using `StandardScaler` to ensure fair comparison across different rating scales.  \n",
    "\n",
    "**Business use case:**  \n",
    "These standardized profiles allow us to cluster hotels into groups with similar performance patterns, which managers can use to:\n",
    "\n",
    "- Identify “true peers” for benchmarking.  \n",
    "- Compare underperforming hotels against high-performing ones in the same cluster to identify best practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8724c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_profiles = filtered_reviews.groupby('offering_id')[['service', 'cleanliness', 'value',\n",
    "                                            'location_rating', 'sleep_quality', 'rooms']].mean()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(hotel_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f4493ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         53699 function calls (53594 primitive calls) in 0.218 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 515 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      3/2    0.000    0.000    0.217    0.108 /Users/aviralgoyal/Desktop/NUS/Courses/Sem 2/IS5126 Hands-On Applied Analytics/A1/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3665(run_code)\n",
      "      3/2    0.000    0.000    0.217    0.108 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.217    0.217 /var/folders/hd/1qp006zn48sdflzfg6_25rtr0000gn/T/ipykernel_61141/866295218.py:1(<module>)\n",
      "        1    0.000    0.000    0.216    0.216 /var/folders/hd/1qp006zn48sdflzfg6_25rtr0000gn/T/ipykernel_61141/866295218.py:1(run_kmeans)\n",
      "        1    0.000    0.000    0.216    0.216 /Users/aviralgoyal/Desktop/NUS/Courses/Sem 2/IS5126 Hands-On Applied Analytics/A1/.venv/lib/python3.13/site-packages/sklearn/base.py:1319(wrapper)\n",
      "        3    0.064    0.021    0.178    0.059 /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py:1970(_run_once)\n",
      "       10    0.000    0.000    0.052    0.005 /Users/aviralgoyal/Desktop/NUS/Courses/Sem 2/IS5126 Hands-On Applied Analytics/A1/.venv/lib/python3.13/site-packages/sklearn/utils/parallel.py:206(wrapper)\n",
      "       10    0.043    0.004    0.051    0.005 /Users/aviralgoyal/Desktop/NUS/Courses/Sem 2/IS5126 Hands-On Applied Analytics/A1/.venv/lib/python3.13/site-packages/sklearn/cluster/_kmeans.py:629(_kmeans_single_lloyd)\n",
      "        1    0.000    0.000    0.045    0.045 /Users/aviralgoyal/Desktop/NUS/Courses/Sem 2/IS5126 Hands-On Applied Analytics/A1/.venv/lib/python3.13/site-packages/joblib/parallel.py:631(cpu_count)\n",
      "        1    0.000    0.000    0.045    0.045 /Users/aviralgoyal/Desktop/NUS/Courses/Sem 2/IS5126 Hands-On Applied Analytics/A1/.venv/lib/python3.13/site-packages/joblib/externals/loky/backend/context.py:78(cpu_count)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_kmeans():\n",
    "    kmeans = KMeans(n_clusters=4, n_init=10, random_state=42)\n",
    "    kmeans.fit(scaled_features)\n",
    "\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "\n",
    "run_kmeans()\n",
    "\n",
    "pr.disable()\n",
    "\n",
    "s = io.StringIO()\n",
    "ps = pstats.Stats(pr, stream=s).sort_stats('cumtime')\n",
    "ps.print_stats(10)\n",
    "\n",
    "print(s.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f42cb",
   "metadata": {},
   "source": [
    "### Interpretation: Clustering Performance\n",
    "\n",
    "The profiling results indicate that the majority of time is spent inside scikit-learn’s KMeans routines and parallel utilities.\n",
    "\n",
    "Key points:\n",
    "\n",
    "- Runtime (~0.2 seconds) is acceptable for periodic recomputation (e.g., daily or weekly).  \n",
    "- For interactive re-clustering with many parameter changes, we might cache results or reduce feature dimensionality.  \n",
    "\n",
    "From a business point of view, clustering is **fast enough** to be a regular part of the analytics pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8d2a44",
   "metadata": {},
   "source": [
    "### Memory Footprint: Cleaned Full Dataset\n",
    "\n",
    "The printed memory usage (~hundreds of MB) quantifies the RAM needed to hold the fully cleaned review dataset in memory.\n",
    "\n",
    "**Business implication:**  \n",
    "Running heavy analytics directly on this full dataset may be challenging on resource-constrained servers, especially if multiple users or notebooks run concurrently. This motivates our filtering and database offloading strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deb073e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage (Filtered Dataset): 461.47 MB\n"
     ]
    }
   ],
   "source": [
    "memory_mb = cleaned_review_df.memory_usage(deep=True).sum() / 1024**2\n",
    "print(\"Memory Usage (Filtered Dataset):\", round(memory_mb, 2), \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728e2242",
   "metadata": {},
   "source": [
    "### Memory Footprint: High-Helpfulness Filtered Dataset\n",
    "\n",
    "After applying the 80th percentile helpfulness filter, memory usage drops to roughly one-quarter of the full cleaned dataset.\n",
    "\n",
    "**Business impact:**  \n",
    "\n",
    "- Lower memory usage means **cheaper infrastructure** (smaller instances) or more capacity for concurrent users.  \n",
    "- It also reduces the risk of slowdowns or crashes during heavy computations, improving reliability of the analytics platform for hotel managers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "635c055c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage (Filtered Dataset): 121.16 MB\n"
     ]
    }
   ],
   "source": [
    "memory_mb = filtered_reviews.memory_usage(deep=True).sum() / 1024**2\n",
    "print(\"Memory Usage (Filtered Dataset):\", round(memory_mb, 2), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78dd9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
